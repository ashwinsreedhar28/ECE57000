{"cells":[{"cell_type":"markdown","metadata":{"id":"Lo68A2ltMkJZ"},"source":["# ECE 570 Assignment 1\n","\n","## **Submission Instructions**\n","All submissions should be uploaded to Gradescope as a PDF version of your current jupyter notebook (see `uploader.ipynb`). See `uploading-instructions.docx` for more information. NOTE: Other ways of converting to PDF may have missing figures or code and could result in grading penalties. In this assignment you only need to submit sections 3, 4, 5 and 6.\n","\n","Remember:\n","1. **Make sure to select the correct pages for each question on Gradescope.** Failure to do so could result in a 0.\n","2. **Make sure your code and output are visible on the PDF.** (should be true if you use the method explained above.)\n","\n","Have fun!"]},{"cell_type":"markdown","metadata":{"id":"O0qw691FVGPi"},"source":["## 1. Background\n","In this assignment, we are trying to do simple sentiment analysis. Sentiment analysis is the process of detecting positive or negative sentiment in text. It’s often used by businesses to detect sentiment in social data, gauge brand reputation, and understand customers.\n","\n","The dataset we will be using is called [***Stanford Sentiment Treebank***](https://nlp.stanford.edu/sentiment/code.html). This dataset is collected from movie reviews on *Rotten Tomatoes* for over 20k sentences. All reviews later got re-organized as distinct phrases with label as number 0.0 to 1.0. Labels can later be divided in to five intervals [0, 0.2], (0.2, 0.4], (0.4, 0.6], (0.6, 0.8], (0.8, 1.0] which means very negative, negative, neutral, positive, very positive, respectively.\n","\n","The dataset we are using in this assignment is a subset of Stanford Sentiment Treebank and consists of **400 phrases**. Train-test dataset split ratio is 50/50 and for either train or test dataset, half of them are extremely positive reviews (have corresponding range (0.9, 1.0]), and the other half are extremely negative reviews (have corresponding range [0.0, 0.1]). Your job is to construct a simple function that takes a single phrase in and outputs whether this phrase has positive or negative sentiment. You can inspect the training dataset to understand the types of phrases that are used.\n","\n","**The goal of this assignment is to attempt to implement a method from the 1st wave of AI, namely handcrafted knowledge systems. Thus, you will be trying to create a rule-based function for this task based on your prior knowledge and some examples from the training dataset.**"]},{"cell_type":"markdown","metadata":{"id":"IuRq9xvxNoX4"},"source":["## 2. Mounting your google drive on Colab\n","Since colab is running on a remote server on Google, you need to mount your google drive on Colab to serve as a 'local directory' to your coding environment. Luckily, it is as simple as two steps! Try to run this block and follow the instructions that pop out.\n","\n","Note: This part is not necessary if you are using your own Python environment or other remote python environment."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"pSTudka7I6gH"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"iKX2M2NfOvPH"},"source":["## 3. Load data (10/100 points)\n","Now, we need to load the data from the \"train.txt\" and \"test.txt\" file. Please change the location for **dir_root** in the following code block to where you saved all your files.\n","\n","Train dataset is stored in the \"train.txt\" file which stores 100 positive phrases and 100 negative phrases. Each line in the file is consist of a phrase and the corresponding sentiment positive(1) or negative(-1) followed by a separation mark '|'.\n","\n","Tips: It is helpful and sometimes necessary to have a separate folder for each assignment!"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"neQW_OYmI_me"},"outputs":[],"source":["import os\n","dir_root = ''\n","#########################        YOUR CODE        #########################\n","#dir_root = '/content/drive/MyDrive/Colab Notebooks/ECE570/Assignment-1'        # change this root directory\n","#########################      END YOUR CODE      #########################                                                                           # for better path controls\n","train_file = os.path.join(dir_root, 'train.txt')                                      # locate the train.txt file"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"B2dxJu94JQ8Z"},"outputs":[{"name":"stdout","output_type":"stream","text":["Phrase \"Astonishingly skillful and moving\" has the sentiment 1\n","Phrase \"are incredibly beautiful to look at\" has the sentiment 1\n","Phrase \"as the most magical and most fun family fare of this or any recent holiday season\" has the sentiment 1\n","Phrase \"It shows that some studios firmly believe that people have lost the ability to think and will forgive any shoddy product as long as there 's a little girl-on-girl action .\" has the sentiment -1\n","Phrase \"Will assuredly rank as one of the cleverest , most deceptively amusing comedies of the year .\" has the sentiment 1\n","Phrase \"disintegrates into a dreary , humorless soap opera\" has the sentiment -1\n","Phrase \"The editing is chaotic , the photography grainy and badly focused , the writing unintentionally hilarious , the direction unfocused ,\" has the sentiment -1\n","Phrase \"The film is often filled with a sense of pure wonderment and excitement not often seen in today 's cinema du sarcasm\" has the sentiment 1\n","Phrase \"is as appalling as any ` comedy ' to ever spill from a projector 's lens\" has the sentiment -1\n","Phrase \"... could easily be called the best Korean film of 2002 .\" has the sentiment 1\n"]}],"source":["# use built-in function \"open\" to read files\n","f = open(train_file, 'r')\n","train_lines = f.readlines()\n","f.close()\n","\n","# construct two lists to store phrases and labels seperately\n","train_data, train_label = [], []\n","\n","#### YOUR CODE HERE ####\n","# Populate the train_data and train_label lists by splitting\n","# each line of train.txt by the \"|\" character and adding\n","# the phrase and label (converted to an int) to the lists\n","with open('train.txt', 'r') as file:\n","    for line in file:\n","        phrase, label = line.strip().split('|')\n","        train_data.append(phrase)\n","        train_label.append(int(label))\n","\n","#### END YOUR CODE ####\n","\n","# preview some data here\n","preview = 10                 # feel free to toggle this number to see more/less data\n","for i in range(preview):\n","    print(f'Phrase \\\"{train_data[i]}\\\" has the sentiment {train_label[i]}')"]},{"cell_type":"markdown","metadata":{"id":"-Oo_MRazCFwL"},"source":["## 4. Manually inspect word frequencies (30/100 points)\n","Now, we need to analyze the data from the \"train.txt\" file. One way to do is to analyze the frequency of individual words in the data based on the occurrence of the word in positive or negative phrases. We can also categorize words as positive or negative based on the number of times that word occurs in positive or negative phrases."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"JCe1Pf1VCGga"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","{'total': 12, 'pos': 12, 'neg': 0}\n","Top most positive words (largest ratio in positive posts)\n"]},{"data":{"text/plain":["[('best', {'total': 12, 'pos': 12, 'neg': 0}),\n"," ('brilliant', {'total': 6, 'pos': 6, 'neg': 0}),\n"," ('films', {'total': 6, 'pos': 6, 'neg': 0}),\n"," ('work', {'total': 5, 'pos': 5, 'neg': 0}),\n"," ('first', {'total': 4, 'pos': 4, 'neg': 0}),\n"," ('love', {'total': 4, 'pos': 4, 'neg': 0}),\n"," ('their', {'total': 4, 'pos': 4, 'neg': 0}),\n"," ('recent', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('often', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('easily', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('performances', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('deserves', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('them', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('funny', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('well', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('triumph', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('adventure', {'total': 3, 'pos': 3, 'neg': 0}),\n"," ('moving', {'total': 2, 'pos': 2, 'neg': 0}),\n"," ('beautiful', {'total': 2, 'pos': 2, 'neg': 0}),\n"," ('season', {'total': 2, 'pos': 2, 'neg': 0})]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Top most negative words (largest ratio in negative posts)\n"]},{"data":{"text/plain":["[('i', {'total': 11, 'pos': 0, 'neg': 11}),\n"," ('bad', {'total': 10, 'pos': 0, 'neg': 10}),\n"," ('worst', {'total': 6, 'pos': 0, 'neg': 6}),\n"," ('my', {'total': 4, 'pos': 0, 'neg': 4}),\n"," ('if', {'total': 4, 'pos': 0, 'neg': 4}),\n"," ('when', {'total': 4, 'pos': 0, 'neg': 4}),\n"," ('product', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('into', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('unlikable', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('utterly', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('pathetic', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('dull', {'total': 3, 'pos': 0, 'neg': 3}),\n"," (':', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('pointless', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('character', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('ugly', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('theater', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('he', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('barely', {'total': 3, 'pos': 0, 'neg': 3}),\n"," ('people', {'total': 2, 'pos': 0, 'neg': 2})]"]},"metadata":{},"output_type":"display_data"}],"source":["# Create word frequency analysis\n","def word_frequency(data, label):\n","    words = dict()\n","    #### YOUR CODE HERE ####\n","    # Calculate the frequency of each word in the given phrases (`data`) and\n","    #   determine the number of the positive or negative occurences based on the\n","    #   corresponding labels (`label`)\n","    # The `words` dictionary should contain each word as key and the total, positive and\n","    #   negative counts as value. e.g. words['best'] = {'total': 2, 'pos': 1, 'neg': 1}\n","    # All words should be converted to lower case\n","    for phrase, lbl in zip(data, label):\n","        for word in phrase.split():\n","            word = word.lower()\n","            if word not in words:\n","                words[word] = {'total': 0, 'pos': 0, 'neg': 0}\n","            words[word]['total'] += 1\n","            if lbl == 1: \n","                words[word]['pos'] += 1\n","            else: \n","                words[word]['neg'] += 1\n","    #### END YOUR CODE ####\n","    return words\n","\n","words =  word_frequency(train_data, train_label)\n","print('total' in words['best'] and 'pos' in words['best'] and 'neg' in words['best']) # True\n","print(words['best']) # {'total': 12, 'pos': 12, 'neg': 0}\n","\n","print('Top most positive words (largest ratio in positive posts)')\n","display(sorted(words.items(), key=lambda x: (x[1]['pos']/x[1]['total'], x[1]['total']), reverse=True)[:20])\n","# [('best', {'total': 12, 'pos': 12, 'neg': 0}),\n","# ('brilliant', {'total': 6, 'pos': 6, 'neg': 0}), ...\n","print('Top most negative words (largest ratio in negative posts)')\n","display(sorted(words.items(), key=lambda x: (x[1]['neg']/x[1]['total'], x[1]['total']), reverse=True)[:20])\n","# [('i', {'total': 11, 'pos': 0, 'neg': 11}),\n","#  ('bad', {'total': 10, 'pos': 0, 'neg': 10}), ..."]},{"cell_type":"markdown","metadata":{"id":"hH3n1eHKhGm6"},"source":["## 5. Handcrafted / Hardcoded Classifier (40/100 points)\n","Please fill in code in the provided skeleton for the function `sentiment_analysis_model` which has the following structure:\n","* Input: a single string `phrase`\n","* output: an integer `-1` or `1`. `-1` stands for negative sentiment and `1` stands for positive sentiment\n","\n","Importantly, this is meant to be like the *first wave of AI* with **hardcoded / handcrafted rules**. You should not use any ML or AI package for this assignment. You can manually look at the train dataset to understand words or phrases that might be positive or negative and can then hardcode these words and possibly weights into your classifier.\n","\n","Second, fill in the function `evaluate` to evaluate the accuracy of your proposed model using the comments in the function.\n","\n","Notes:\n","1. Try to constrain your code for `sentiment_analysis_model` to within **50 lines without importing any additional packages** (i.e, this assignment does not require you to perform any complicated model analysis)\n","2. You can view all the training phrases by opening file *'train.txt'* in the provided zip file.\n","3. Throughout the design of your algorithm, **you should only have access to the train dataset** stored in \"train.txt\". The test dataset stored in 'test.npy' should only be used in the next evaluation section. You can think that train dataset is what we would actually have to learn from (like course materials and lectures) while test is new data that simulates real-world posts (where we wouldn’t usually know the true labels).\n","\n","You might find the following hints helpful (not required to use them):\n","1. Inspect the frequency table for the words in the training dataset based on your outputs above.\n","2. You might want to use the Python keyword `in` for seeing if one string is in another.\n","3. You might want to use the `lower()` or `upper()` string functions.\n","4. Manually define (i.e., hand-craft) your own rules/criteria for good vs. bad review (e.g. you may want to consider words that are usually good or bad). You can also use the list of positive and negative words that you determined in the previous section for defining the criteria."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"TNCrqyudK5NU"},"outputs":[{"name":"stdout","output_type":"stream","text":["Your method has the training accuracy of 78.0%\n"]}],"source":["def sentiment_analysis_model(phrase):\n","    \"\"\"\n","    sentiment_analysis function determines whether a phrase is positive (1) or negative (-1).\n","\n","    :param1(string) phrase: a single phrase in the format of string\n","    :return(int)          : 1 if the phrase is postive or -1 if the phrase is negative\n","    \"\"\"\n","\n","    #########################        YOUR CODE        #########################\n","    # Hardcoded positive and negative word lists based on manual analysis of train.txt\n","    positive_words = [\"best\", \"brilliant\", \"films\", \"work\", \"first\", \"love\", \"their\", \"recent\", \"often\", \"easily\", \"performances\", \"deserves\", \"them\", \"funny\", \"well\", \"triumph\", \"adventure\", \"moving\", \"beautiful\", \"season\", \"amusing\"]\n","    negative_words = [\"i\", \"bad\", \"worst\", \"my\", \"if\", \"when\", \"product\", \"into\", \"unlikeable\", \"utterly\", \"pathetic\", \"dull\", \"pointless\", \"character\", \"ugly\", \"theater\", \":\", \"he\", \"barely\", \"people\"]\n","    tokens = [word.lower() for word in phrase.split()]\n","    score = sum([1 for token in tokens if token in positive_words]) - sum([1 for token in tokens if token in negative_words])\n","\n","    if score > 0: \n","        return 1\n","    \n","    return -1\n","\n","    #########################      END YOUR CODE      #########################\n","\n","\n","def evaluate(func, data, label):\n","    #########################       YOUR CODE      #########################\n","    # Evaluate the accuracy of the model (passed as the function `func`)\n","    #   on the given phrases (`data`) and corresponding labels (`label`)\n","    # For each phrase in `data`, compute the model's prediction for the phrase\n","    #   and then determine if the prediction is equal to the true corresponding\n","    #   label from `label`.\n","    # Count the number of correct predictions and divide by the total number\n","    #   of phrases to get the accuracy.\n","    correct_predictions = sum([1 for phrase, lbl in zip(data, label) if func(phrase) == lbl])\n","    #########################   END YOUR CODE      #########################\n","    accuracy = correct_predictions / len(data)\n","    \n","    return accuracy\n","\n","train_acc = evaluate(sentiment_analysis_model, train_data, train_label)\n","print(f\"Your method has the training accuracy of {train_acc*100}%\")"]},{"cell_type":"markdown","metadata":{"id":"AadzsP3uRWib"},"source":["## 6. Evaluate (20/100 points)\n","You may already notice that there is an extra evaluation function in the above coding block which helps calculate the accuracy for your algorithm in the training dataset. The metric that we used to evaluate is straightforward:    \n","$$Accuracy = # of correct prediction / # of total cases$$\n","Now, let's test the performances of your algorithm in test dataset!\n","Try to get the **test accuracy** to be higher than 55% to receive **full credit**!\n","\n","Note: You should not have the accuracy to be lower than 50%!"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"JaoWgyj2K1TR"},"outputs":[{"name":"stdout","output_type":"stream","text":["Your method has the test accuracy of 60.5%\n"]}],"source":["import sys\n","sys.path.append(dir_root)\n","from top_classified_file import super_secret_function\n","\n","test_dir = os.path.join(dir_root, 'test.npy')\n","test_acc = super_secret_function(test_dir, sentiment_analysis_model)\n","\n","print(f\"Your method has the test accuracy of {test_acc*100}%\")"]},{"cell_type":"markdown","metadata":{"id":"CdSf3f-uS5jt"},"source":["## 7. Did you notice something interesting? (Optional)\n","1. During your design, does training accuracy always a little bit higher than test accuracy? Why?\n","2. Does the sentiment analysis task a little bit harder than you expected?\n","3. ... something else you would like to talk about"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":0}
